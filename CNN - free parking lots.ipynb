{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To work with nd-arrays\n",
    "import numpy\n",
    "\n",
    "#To plot graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#To use operating system dependent functionality\n",
    "import os \n",
    "\n",
    "#To build neural network models\n",
    "import keras\n",
    "\n",
    "#Deep learning models with pre-trained weights\n",
    "from keras import applications \n",
    "\n",
    "#To perform image augmentation-> scaling, rotation...\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "#To minimize loss function\n",
    "from keras import optimizers \n",
    "\n",
    "#Iporting different models in keras\n",
    "from keras.models import Sequential, Model \n",
    "\n",
    "#To reshape the layers of the model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D \n",
    "\n",
    "#To import (three) backend implementations of keras\n",
    "from keras import backend as k \n",
    "\n",
    "#To fix bugs in the model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping \n",
    "\n",
    "#To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#For reproducibility\n",
    "numpy.random.seed(1) # NumPy\n",
    "import random\n",
    "random.seed(2) # Python\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(3) # Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Test and Train Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_train = 0\n",
    "files_validation = 0\n",
    "\n",
    "#To get current working directory\n",
    "cwd = os.getcwd()\n",
    "#Setting the path pointing to the training set\n",
    "folder = 'training_data/train'\n",
    "\n",
    "#To count number of files in training set\n",
    "for sub_folder in os.listdir(folder):\n",
    "    #os.path.join concatenates path by appropirately adding '/'\n",
    "    root, dirs, files = next(os.walk(os.path.join(folder,sub_folder)))\n",
    "    files_train += len(files)\n",
    "\n",
    "#To count number of files in validation set\n",
    "folder = 'training_data/validate'\n",
    "for sub_folder in os.listdir(folder):\n",
    "    #os.path.join concatenates path by appropirately adding '/'\n",
    "    root, dirs, files = next(os.walk(os.path.join(folder,sub_folder)))\n",
    "    files_validation += len(files)\n",
    "\n",
    "#Total number of training files and validation files\n",
    "print(files_train,files_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Setting Key Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting image height and width\n",
    "img_width, img_height = 48, 48\n",
    "#Setting training and validation directories\n",
    "train_data_dir = \"training_data/train\"\n",
    "validation_data_dir = \"training_data/validate\"\n",
    "#Setting number of training and validation samples\n",
    "nb_train_samples = files_train\n",
    "nb_validation_samples = files_validation\n",
    "#Number of samples used per pass\n",
    "batch_size = 64\n",
    "#1 epoch-> 1 complete forward and back pass\n",
    "epochs = 100\n",
    "#We have 2 classes only-> EMPTY and OCCUPIED\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build model on top of a trained VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using VGG16 architecture - 16 layer model\n",
    "    #imagenet-> pre-defined model/project to train and assign weights also provides annotations for objects in an image\n",
    "    #input_shape-> should have exactly 3 input channels(R,G,B)\n",
    "    #include_shape=False-> when we use pretrained models\n",
    "model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "    #Freezing layers will reduce computaional time\n",
    "    #Dataset is small and data similarity is also less.\n",
    "    #We need to train inly the basic features which will be same for all images\n",
    "    #So we freeze top 5 layers\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "#To show the training status of each layer\n",
    "for layer in model.layers:\n",
    "    print(layer,layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Reshape output and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.output\n",
    "\n",
    "#__________________________________________________________NOTE:______________________________________________________________\n",
    "#There are different types of layers like dense, drop\n",
    "    #dense-> fully connected layers, all nodes are connected to every other nodes in subsequent layer\n",
    "      #We use 16 as output dimension for dense-> 2 classes*8 = 16\n",
    "    #drop-> during training some random number of nodes will be dropped to prevent overfitting\n",
    "    #flatten-> reshapes output equal to number of elements in input\n",
    "        #flatten  -> (5,3)->(1,15)\n",
    "        #dense(16)-> (1,15)->(1,16)\n",
    "#__________________________________________________________NOTE:______________________________________________________________       \n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "#converting flattened layer model into dense(2)\n",
    "predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model\n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model\n",
    "    #use categorical_crossentropy as model returns soft probabilities for each sample\n",
    "    #Stochastic gradient boosting-> optimizer used while compiling the model\n",
    "        #lr-> learning rate\n",
    "        #momentum-> to smoothen update; should be high to give more weightage to past gradients - faster convergence\n",
    "        #decay-> to lessen the learning rate gradually to find the optimal result\n",
    "            #decay formula-> lr = self.lr * (1. / (1. + decay * epoch))\n",
    "    #mean absolute error is used as metric to computer errors\n",
    "lr0=0.1\n",
    "decay_rate = lr0/epochs\n",
    "model_final.compile(loss = \"categorical_crossentropy\", \n",
    "                optimizer = optimizers.SGD(lr=lr0, momentum=0.9, decay=decay_rate, nesterov=True), metrics=[\"mae\",\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Build Image data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the train and validation generators with data Augumentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "#To scale RGB values in range of 0 to 1\n",
    "rescale = 1./255,\n",
    "#to flip input iage horizontally-> efficient augmentation\n",
    "horizontal_flip = True,\n",
    "#points outside boundaries are filled according similar to nearest one to the boundary\n",
    "fill_mode = \"nearest\",\n",
    "#to zoom \n",
    "zoom_range = 0.1,\n",
    "#to shift image hoizontally (0.1 fraction of entire width)\n",
    "width_shift_range = 0.1,\n",
    "#to shift image vertically (0.1 fraction of entire height)\n",
    "height_shift_range=0.1,\n",
    "#Degree range for random rotations\n",
    "rotation_range=5)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "#To scale RGB values in range of 0 to 1\n",
    "rescale = 1./255,\n",
    "#to flip input iage horizontally-> efficient augmentation\n",
    "horizontal_flip = True,\n",
    "#points outside boundaries are filled according similar to nearest one to the boundary\n",
    "fill_mode = \"nearest\",\n",
    "#to zoom \n",
    "zoom_range = 0.1,\n",
    "#to shift image hoizontally (0.1 fraction of entire width)\n",
    "width_shift_range = 0.1,\n",
    "#to shift image vertically (0.1 fraction of entire height)\n",
    "height_shift_range=0.1,\n",
    "#Degree range for random rotations\n",
    "rotation_range=5)\n",
    "\n",
    "#Setting the source and specifications for the train_generator to work on\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "class_mode = \"categorical\")\n",
    "\n",
    "#Setting the source and specifications for the test_generator to work on\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"SK7_parking_lot.h5\", #h5py file format to store results\n",
    "                             monitor='val_acc', #accuracy computed on validaiton dataset\n",
    "                             verbose=1, #logs are dispalyed\n",
    "                             save_best_only=True, #Latest best model will not be overwritten \n",
    "                             save_weights_only=False, #If false full model will be saved. else only weights are saved\n",
    "                             mode='auto', #If auto, automatically inferred from monitor method\n",
    "                             period=1) #No of epochs between each checkpoint\n",
    "\n",
    "early = EarlyStopping(monitor='val_acc', #accuracy computed on validaiton dataset\n",
    "                      min_delta=0, #if subsequent iteration has no change in quantity, then considered as no improvement \n",
    "                      patience=2, #no of consecutive no improvement iterations allowed\n",
    "                      verbose=1, #logs are dispalyed\n",
    "                      mode='auto') #If auto, automatically inferred from monitor method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SK7_CNN_model = model_final.fit_generator(\n",
    "train_generator, #Training data to be used is set using train_generator built\n",
    "    \n",
    "    #To mark the beginnning of next epoch, since keras is not aware of epoch\n",
    "    #Keras function is loop infinity, so it is not aware of the begining and end of epoch    \n",
    "steps_per_epoch = nb_train_samples//batch_size, \n",
    "    \n",
    "epochs = epochs, #Number of epochs\n",
    "validation_data = validation_generator, #Validation data to be used is set using validation_generator built\n",
    "\n",
    "workers=1,\n",
    "use_multiprocessing=False,\n",
    "callbacks = [checkpoint, early]) #To save model and constraint to stop training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.Plotting graph for the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SK7_CNN_model.history.keys())\n",
    "plt.plot(SK7_CNN_model.history['acc'])\n",
    "plt.plot(SK7_CNN_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(SK7_CNN_model.history['loss'])\n",
    "plt.plot(SK7_CNN_model.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
